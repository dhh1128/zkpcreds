<!DOCTYPE html>
<html>
<head>
    <title>Rebuttal to Arnold and Longley's ZKP article</title>
    <link rel="stylesheet" href="default.css">
</head>
<body>

<header id="banner">
    <h1>Rebuttal to Arnold and Longley's ZKP article</h1>
    <h2>Daniel Hardman, January 2020</h2>
</header>

<article>
    <details>
        <summary>Background</summary>
        <section class="more">
            <p>
                Arnold and Longley published an article (hereafter, "the article") that claims ZKP-oriented credentials are fatally flawed. The authors assert that such credentials are inherently anonymizing, and that this property enables fraud by holders.
            </p>

            <p>
                The authors' formulation of tradeoffs into a trust paradox is insightful (though <a href="#point3">flawed</a>). We agree on a few other points, too (see <a href="#summary">Summary</a>). However, the article's application of the paradox to ZKP-oriented credentials is deeply misleading. It perpetuates misunderstanding of the technology it criticizes, propagating baseless FUD. It needs to be debunked.
            </p>

            <p>
                Unfortunately, picking apart a narrative this complex demands thoughtful and sustained attention. I apologize in advance for the eye-glazing detail. I've organized this doc into expandable sections, so you can skim or dive deep as desired. (Please note that to limit scope, this rebuttal focuses only on points raised in the Arnold Longley article. The larger debate about credential models includes many additional topics. See <a href="#learningmore">Learning More</a> for links.)
            </p>

            <p>
                Arnold and Longley are critics of ZKP-oriented credentials, and have built an entire ecosystem around a competing technology. I am a ZKP proponent, and have built the opposite. Of course you should apply the same skeptical filter to both of us. Don't forget to evaluate sources in the Arnold Longley article and here in my rebuttal (see <a href="#endnotes">Endnotes</a>).
            </p>
        </section>
    </details>

    <details>
        <summary id="point1">1. The article defines "zero-knowledge proofs" wrong, setting up a basic fallacy.</summary>
        <section class="more">
            <p>
                This is the first and most fundamental flaw in Arnold and Longley's thinking. It taints nearly everything in the article. They characterize zero-knowledge proofs like this:
            </p>
            <blockquote>
                ZKPs allow provers to prove they possess a certain piece of knowledge with the verifier learning nothing more than this fact.<span class="ref">[AL, Introduction]</span>
            </blockquote>
            <p>
                Notice that Arnold and Longley cite nobody here. They can't, because this is NOT a good definition of zero-knowledge proofs in general, or of ZKPs in credentialing ecosystems; instead, it describes a subcategory of ZKP called a <dfn>zero-knowledge proof <em style="text-decoration:underline">of knowledge</em></dfn> (<dfn>ZKPOK</dfn>)<span class="ref">[<a id="ref1" href="#note1">1</a>]</span>. It assumes a single fact in isolation, rather than the common case where primitive ZKPOKs are composed into sophisticated systems (think ZK-SNARK circuits and predicates). Here is the definition of the more general concept, from the seminal paper on ZKPs:
            </p>
            <blockquote>
                Zero-knowledge proofs are defined as those proofs that convey no additional knowledge other than the correctness of the proposition in question.<span class="ref">[<a id="ref2" href="#note2">2</a>]</span>
            </blockquote>
            <p>
                Note the difference: <em>ZKPs aren't limited to proofs of possession of a single fact</em>. The knowledge in question can be complex<span class="ref">[<a id="refb" href="#noteb">b</a>]</span> (e.g., a proposition about the truth and relatedness of many assertions by an issuer about a subject), and it need not demonstrate that the prover knows something.<span class="ref">[<a id="refa" href="#notea">a</a>]</span> Rather, the defining characteristic of ZKPs is that they don't leak "additional knowledge":
            </p>
            <figure id="compare-defs">
                <img src="compare-defs.png" alt="AL def is subset of actual def that matters">
                <figcaption>Figure 1: The definition of zero-knowledge proofs in the AL article is far too narrow.</figcaption>
            </figure>
            <p>
                What it would take for a proof to fall outside the largest oval in the diagram above? <em>It would have to leak knowledge beyond what circumstances require.</em> In other words, it would have to be careless or promiscious or clumsy. The ZKP standard &mdash; <em>in the interests of privacy, be careful to never prove something beyond what's required</em> &mdash; is simply the familiar cybersecurity principle to trust as little as possible.<span class="ref">[<a id="refe" href="#notee">e</a>]</span> This is the standard Arnold and Longley would have us believe is fatally flawed?
            </p>
            <p>
                Large portions of Arnold and Longley's reasoning is based on a <dfn>composition fallacy</dfn> that if something is true about a subcategory (simple ZKPOKs with obvious limits), it must be true about its parent category (complex, rich ZKPs).<span class="ref">[<a id="ref4" href="#note4">4</a>]</span>. They argue from a basic misunderstanding of what is possible with ZKP-oriented credentials, and what would violate the actual standard of zero knowledge rather than the narrow standard they assert. Most of the article's section 2 falls apart due to this flaw.
            </p>

            <details>
                <summary id="point1.1">1.1 The difference between these two definitions is substantial.</summary>
                <section class="more">
                    <p>
                        Under the flawed model imagined by Arnold and Longley, all of the following features are illegal in a ZKP &mdash; even though they're mainstream features in the tech they criticize:
                    </p>

                    <ul>
                        <li>Prove the equality or inequality of two undisclosed values<span class="ref">[<a id="ref5" href="#note5">5</a>]</span></li>
                        <li>Prove the relative ordering of two undisclosed values, or of one disclosed and one undisclosed value<span class="ref">[<a id="ref6" href="#note6">6</a>]</span></li>
                        <li>Prove membership of an undisclosed value in a set<span class="ref">[<a id="ref7" href="#note7">7</a>]</span></li>
                        <li>Disclose an actual value, and prove its relationship to values that are not disclosed.<span class="ref">[<a id="ref8" href="#note8">8</a>]</span></li>
                    </ul>

                    <p>
                        Note especially the last item in that list: <em>You can disclose actual values in zero knowledge</em>. If a verifier needs to know an identifier for the prover, there's a ZKP for that. It may or may not be a ZKPOK, but it's still zero knowledge, <em>as long as the value of the identifier is part of the legitimate scope of the proof</em>, and that scope is never exceeded.
                    </p>
                </section>
            </details>
            <details>
                <summary id="point1.2">1.2 Evaluating whether "additional knowledge" leaks can only be done against situational requirements, not the article's tbought experiment.</summary>
                <section class="more">
                    <p>The article asks us to evaluate zero knowledge by logical inference from an abstract definition. This is misdirection. Real evaluation decides what is necessary knowledge and what is additional, leaked knowledge by taking into account the requirements in a given situation:</p>
                    <ul>
                        <li>
                            A perfect proof of exactly and only “over 18” <em>is not zero-knowledge</em> if the actual proposition that needed proving was “over 16” — no matter what technique is used and what its mathematical guarantees might be. This is because two extra years of precision are leaked about the age.
                        </li>
                        <li>
                            A proof that discloses Alice’s genome and full medical history, her facts of birth, biometrics, everything from her passport, and the full history of all interactions she’s ever had with her government <em>is zero-knowledge</em> &mdash; if and only if the necessary facts are the ones proved, and if that proof did not go beyond what circumstances required.
                        </li>
                    </ul>
                </section>
            </details>
            <details>
                <summary id="point1.3">1.3 Revealing an identifier can be (and is!) done in zero-knowledge.</summary>
                <section class="more">
                    <p>
                        Revealing something and claiming zero-knowledge might seem contradictory, but it's not.
                    </p>
                    <ul>
                        <li>The ABC4Trust system architecture includes an entire section, 2.5, about this possibility.</li>
                        <li>The Hyperledger Indy ecosystem has supported disclosure of identifiers since version 1.0.</li>
                        <li>The company I work for, Evernym, has been demoing use cases that involve ZKP-based disclosure of identifiers of varying strengths (names, driver's license numbers, etc) since Jan 2018.</li>
                        <li>The world's first production deployment of Verifiable Credentials, the <a target="_blank" href="https://vonx.io/">Verifiable Organizations Network in British Columbia</a>, issued Indy-based ZKP credentials with strong identifiers (e.g., a business's government-issued ID) the day it went live in 2018, and has been doing so ever since. These credentials are regularly used to prove things about businesses, where the requests for proof include disclosure of those identifiers.</li>
                    </ul>
                    <p>
                        To understand how this could be a feature of ZKP-oriented credentials, consider a scenario where a particular context requires you to prove:
                    </p>
                    <ol>
                        <li>The name on your passport</li>
                        <li>That this value was signed by nation X</li>
                    </ol>
                    <p>The zero-knowledge way to satisfy these requirements is to reveal the name (weakly identifying), and to prove that the name has the necessary relationship to a larger set of assertions in the passport that are not revealed &mdash; but to establish the existence and nature of the signature without revealing its actual value (not identifying at all). The non-zero-knowledge way is to reveal both values (strongly identifying, since the signature value is globally unique). Both methods reveal the name; the non-ZKP approach leaks something extra and lessens privacy as a result.
                    </p>
                    <figure id="zkp-scope">
                        <img src="zkp-scope.png" alt="ZKPs can reveal identifiers.">
                        <figcaption>Figure 3: Proving a signed value in a ZKP and a non-ZKP way.</figcaption>
                    </figure>
                    <p>(By the way, non-ZKP-credentials would typically reveal much more than just a name and a signature in this scenario; the most common approach would be to reveal all the other fields in your passport, too. This is part of the larger discussion about why ZKP's answer for selective disclosure is compelling &mdash; but since Arnold and Longley don't argue it, I'll just note it here. See <a href="#learningmore">Learning More</a> to dive deeper.)</p>
                </section>
            </details>
            <details>
                <summary id="point1.4">1.4 The bad definition undermines the analysis.</summary>
                <section class="more">
                    <p>Numerous inaccuracies arise in the article due to Arnold and Longley's straw man meaning. An exhaustive catalog isn't worthwhile, but two important examples are:</p>
                    <blockquote>
                        However, because such a proof provides zero knowledge, it is repudiable &mdash; a key difference from the traditional digital signature approach. <span class="ref">[Arnold and Longley, section 2.4]</span></li>
                    </blockquote>
                    <p>And:</p>
                    <blockquote>
                        ZKP ABC systems aim to provide privacy to the user by exposing no additional information beyond what is strictly needed by the verifier. However, a user cannot prove in zero-knowledge that they possess a certain attribute. <span class="ref">[Arnold and Longley, Conclusion]</span></li>
                    </blockquote>
                    <p>
                        If ZKP-oriented credentials were purely limited to primitive ZKPOKs, claims like these would be true. But they're not. We've corrected the mistaken conception about disclosure in ZKPs (<a href="#point1.3">point 1.3</a>); for more about repudiation, see point X.
                    </p>
                </section>
            </details>
        </section>
    </details>

    <details>
        <summary id="point2">2. It quotes experts out of context to build a straw man model of anonymity.</summary>
        <section class="more">
            <p>
                A pivotal claim in the article is that ZKP-oriented credentials commit both parties in a proving interaction to the absolute anonymity of the prover. As a contributor to ZKP-oriented credential technology, I reject this as exaggeration (see <a href="#point12">point 1.2</a> and <a href="#point13">point 1.3</a>), but Arnold and Longley insist upon it. They quote ZKP experts (from a 148-page document, without citing a page number) to make the point:
            </p>
            <blockquote>
                As mentioned in the introduction, efforts are being made to use ZKPs to limit the amount of additional correlatable information the user shares with the verifier. The idea is for a user to prove they have access to a valid credential without revealing the issuer's signature or the holder's identifier. Such credential presentations are "<span style="color:blue">cryptographically unlinkable and untraceable, meaning that verifiers cannot tell whether two presentation tokens were derived from the same or from different credentials, and that issuers cannot trace a presentation token back to the issuance of the underlying credentials.</span>"<span class="ref">[Arnold and Longley, section 2.4, expert subquote in blue]</span>
            </blockquote>
            <p>
                The article then conflates "cryptographically unlinkable" in the quote with <em>general</em> unlinkability (another composition fallacy like the one discussed in <a href="#point1">point 1</a>), and uses this to justify their claim of anonymity:
            </p>
            <blockquote>
                For the purpose of unlinkability, a presentation must not include any protocol information that could uniquely identify the user. In this way, ZKPs anonymize the holder of the credential, rendering their activity untraceable.<span class="ref">[Arnold and Longley, section 2.4]</span>
            </blockquote>
            <p>
                To reinforce the importance of this claimed categorical guarantee, Arnold and Longley repeat a subset of the quote a few paragraphs later:
            </p>
            <blockquote>
                Remember, "<span style="color:blue">verifiers cannot tell whether two presentation tokens were derived from the same or from different credentials.</span>"<span class="ref">[Arnold and Longley, Example 2.5, expert subquote in blue]</span>
            </blockquote>
            <p>
                Note where the quotation marks occur. Only blue text is from the experts; Arnold and Longley begin quoting halfway through a sentence, gluing their own framing of a concept to a description from the experts. So do they fairly represent the intent of the original? Here is the blue quote in its larger context (from page 17 of the ABC4Trust documentation):
            </p>
            <blockquote>
                <p>
                    Presentation tokens based on Privacy-ABCs are in principle <span style="color:blue">cryptographically unlinkable and untraceable, meaning that Verifiers cannot tell whether two presentation tokens were derived from the same or from different credentials, and that Issuers cannot trace a presentation token back to the issuance of the underlying credentials.</span> However, we will later discuss additional mechanisms that, with the User’s consent, enable a dedicated third party to recover this link again (see Section 2.5 for more details).
                </p>
                <p>
                    Obviously, presentation tokens are only as unlinkable as the information they intentionally reveal. For example, tokens that explicitly reveal a unique attribute (e.g., the User’s social security number) are fully linkable. Moreover, pseudonyms and inspection can be used to purposely create linkability across presentation tokens (e.g., to maintain state across sessions by the same User) and create traceability of presentation tokens (e.g., for accountability reasons in case of abuse). Finally, Privacy-ABCs have to be combined with anonymous communication channels (e.g., Tor onion routing) to avoid linkability in the “layers below”, e.g., by the IP addresses in the underlying communication channels or by the physical characteristics of the hardware device on which the tokens were generated.<span class="ref">[<a id="ref9" href="#note9">9</a>]</span>
                </p>
            </blockquote>
            <p>
                What the experts actually say is a lot more nuanced than what the AL article asserts: ZKP-oriented presentations are unlinkable <em>"in principle ... [h]owever..."</em>.
            </p>
            <p>
                An important nuance that's entirely suppressed by Arnold and Longley is the moderating effect of non-cryptographic factors like disclosed data, communication channels, history, and other protocols. The effect of such factors can be profound. It is one reason why the zeroness in ZKPs must be evaluated in context (see <a href="#point1.2">point 1.2</a>): non-cryptographic factors can also be evaluated only in context.
            </p>
            <figure id="reasonable-privacy">
                <img src="reasonable-privacy.png" alt="AL def is subset of actual def that matters">
                <figcaption>Figure 2: The actual privacy delivered by ZKP-oriented credentials vs. the theoretical privacy target claimed by Arnold and Longley. Notice the vertical as well as the horizontal separation.</figcaption>
            </figure>
            <p>
                This simplistic view of anonymity is a big deal. Arnold and Longley's whole argument rests on the assumption that a prover isn't vulnerable when they're perfectly anonymous, because their reputation isn't at risk &mdash; and that the sweet spot in the privacy vs. vulnerability tradeoff is a point where some privacy MUST be traded away in the cryptography. But the experts they misquote are careful to itemize some ways that absolute anonymity is only a theory anyway; according to these experts, practical factors move an interaction toward the middle of Arnold and Longley's curve independent of cryptography. The AL article is arguing a straw man, making much of it irrelevant.
            </p>
            <details>
                <summary id="point2.1">2.1 The difference between “real world” and theory is significant.</summary>
                <section class="more">
                    <p>In a physical and human world, exploits aren’t as easy as they look on paper, vulnerability to other humans is rarely zero, and imperfect proof is often fine.</p>

                    <p>We can sometimes infer things from ZKPs, no matter how pure the math is. Consider proving just your nationality in zero knowledge. Normally this would preserve a lot of privacy--but if you do it on the International Space Station, it could be uniquely identifying. Likewise, if I ask for a ZKP from a remote party and I get a response 10 milliseconds later, I can reasonably infer that the party I’m interacting with is located within 5 light milliseconds (1500 km) of my current location &mdash; light couldn’t have carried the interaction any faster. With somewhat less assurance, I can guess that the party is on my local network, since ping times are usually not that fast for parties many network hops distant.</p>

                    <p>ZKPs presented in person &mdash; Alice requesting access to a voting booth, for example &mdash; are an important use case that the article doesn’t consider at all. Such interactions carry significant amounts of context besides what’s embodied in mathematics. Regardless of ZKP anonymity, malicious Alice probably can’t vote twice with the same credential, if she appears before the same election official twice in quick succession.</p>

                    <p>What this means is that in “real world” usage, ZKPs target and deliver “pretty good” zero knowledge, not the anonymity that Arnold and Longley would have us believe. This "pretty good" zero knowledge combines with verifier requirements for "pretty good" assurance to allow reasonable behaviors that protect everyone.</p>

                    <p>For an example of mutual accommodation with "pretty good" assurance, consider tobacco regulations in the United States. These regulations make it illegal to sell tobacco products to anyone under age 21. However, the regulation settles for fuzzy enforcement &mdash; vendors are supposed to demand photo ID from anyone who appears to be younger than 27.<span class="ref">[<a id="refc" href="#notec">c</a>]</span> Judging “under 27” is left to the vendor, and auditing is unpredictable. The vendor and the person buying tobacco are mutually vulnerable to one another in a dynamic way; each balances risk versus benefit when deciding whether to strengthen proof. Undoubtedly some fraud occurs, but a significant deterrent effect is also created.<span class="ref">[<a id="refd" href="#noted">d</a>]</span> Because ZKP-oriented credentials allow granular escalation of proof, they are a natural fit for this sort of situation, even though the guarantees of the interaction don't match a mathematical ideal.</p>
                </section>
            </details>
        </section>
    </details>

    <details>
        <summary id="point3">3. It oversimplifies the basis of trust.</summary>
        <section class="more">
            <p>
                Arnold and Longley assert a general principle that they call the Trust Paradox: "No trust without vulnerability."<span class="ref">[section 2.1]</span> They elaborate two key examples of this paradox in action, across sections 2.1, 2.2, and 2.5:</p>
            <ul>
                <li>An issuer can be trusted if they risk their reputation as an honest credential signer.</li>
                <li>A prover can be trusted if they degrade privacy enough to risk their reputation as an honest credential holder.</li>
            </ul>
            <p>This is fine, as far as it goes &mdash; but the thinking is too narrow. Trust in others arises out of <em>confidence in constraints</em>; reputation risk is only one of many constraints on human behavior.
            </p>
            <ul>
                <li>The public trusts people who operate Bitcoin miners because their machines are constrained by an ungameable proof-of-work algorithm &mdash; not because of reputation risk.</li>
                <li>A bank trusts employees not to steal cash from the vault after hours because the vault has a time lock that can't be overridden &mdash; not because of reputation risk.</li>
                <li>A detective trusts a suspect's innocence because fingerprints don't match &mdash; not because of reputation risk.</li>
                <li>Acme Corp trusts a newly hired salesman to work hard because he's paid on commission &mdash; not because of reputation risk.</li>
                <li>A mom trusts her son not to put his hand in a candle's open flame because it will hurt &mdash; not because of reputation risk.</li>
                <li>Kidnappers trust family members to pay a ransom because the victim is dear &mdash; not because of reputation risk.</li>
            </ul>
            <p>
                A better formulation of the Trust Paradox would be: "No trust without constraints." Despite Arnold and Longley's claims, ZKP-oriented credentials let prover reputation be risked in interactions, if circumstances make that constraint desirable. ZKP credentials also offer many other options for constraining the prover to achieve trust. See <a href="#point1.3">point 1.3</a>, <a href="#point4.1">point 4.1</a>, <a href="#point4.2">point 4.2</a>, and <a href="#point4.3">point 4.3</a>; also, <a href="#learningmore">Learning More</a>.
            </p>
        </section>
    </details>

    <details>
        <summary id="point4">4. It mischaracterizes link secrets.</summary>
        <section class="more">
            <p>
                The target of much of Arnold and Longley's FUD is a mechanism that ZKP mechanisms use to bind credentials to their holder. The article calls this mechanism <dfn>correlation secrets</dfn> in some places, and <dfn>link secrets</dfn> in others. These are synonyms; we'll use the shorter term.
            </p>
            <p>
                Link secrets are large random numbers that only a holder is supposed to know. The math behind them is a bit esoteric, and it trips up Arnold and Longley (see <a href="#point8">point 8</a>). A simple though imperfect<span class="ref">[<a id="refj" href="#notej">j</a>]</span> analogy is to think of them like a tool that's used to generate watermarks. A holder and issuer cooperatively use link secrets to "watermark" credentials at issuance time, to bind them uniquely to the holder. Later, during a proving interaction, the prover shows the verifier in zero knowledge that they can generate a "watermark" that shares carefully selected characteristics with the original. This is not possible unless the prover knows the holder's secret; thus, it is evidence that the credentials used for proving belong to them instead of someone else.
            </p>
            <figure id="watermark">
                <img src="watermark.jpg" alt="watermark on a 1000-yen note">
                <figcaption>Figure 3: Watermark of Hideyo Noguchi on a Series E 1000-yen note. The presence of such watermarks is partial evidence that a bill is not counterfeit. An inability to produce congruent likenesses suggests fraudsters pretending to be Japan's minting office. (Image credit: <a target="_blank" href="https://commons.wikimedia.org/wiki/File:Series_E_1,000_yen_note_watermark.jpg">Numister, Wikimedia Commons</a>, CC-SA Intl 4.0)</figcaption>
            </figure>
            <p>
                Arnold and Longley are correct to claim that the guarantees associated with link secrets come with caveats. So do watermarks, of course. But neither link secrets nor watermarks are useless; they are both components of a larger strategy to eliminate fraud that the article distorts:
            </p>
            <table>
                <tr><th style="width:30%">Article claim</th><th>Fact</th></tr>
                <tr>
                    <td>Correlation secrets are the only mechanism that ZKP-oriented credentials use to prevent fraudulent transfer.</td>
                    <td>Plenty of mechanisms exist to bind ZKP-oriented credentials to their legitimate holder. This includes the same choices available with non-ZKP-oriented credentials: disclosure of identifiers or other data fields to make reputation vulnerable (see <a href="#point1.3">point 1.3</a>). It also includes biometrics (see <a href="#point4.1">point 4.1</a> below). Each mechanism has tradeoffs. Link secrets are just another option, with another set of tradeoffs. ZKP creds contain them, and ZKPs reference them, but verifiers who don't like them can ignore them. Link secrets can also be combined with other options; they are not mutually exclusive.</td>
                </tr>
                <tr>
                    <td>Provers are forced to accept link secret guarantees if they interact with a prover that uses ZKPs.</td>
                    <td>Nobody forces a merchant to accept currency as legitimate using just a watermark as evidence; merchants can set whatever standard for themselves they like. Similarly, verifiers &mdash; not the tech they use &mdash; decide what level of assurance will satisfy them (see <a href="#point6.2">point 6.2</a>). If they want assurances beyond link secrets, they are perfectly able to demand them &mdash; and provers can provide such assurances inside the ZKP-oriented credential ecosystem.</td>
                </tr>
                <tr>
                    <td>It's easy to share link secrets, and hard to detect that they've been shared.</td>
                    <td>It is true that the mechanics of sharing secrets (of any kind) are easy, but incentives can drastically alter whether link secret transfer is likely (see <a href="#point4.2">point 4.2</a>). Fraudulent reuse of these secrets is detectable at the option of the verifier (<a href="#point4.3">point 4.3</a>).</td>
                </tr>
            </table>
            <details>
                <summary id="point4.1">4.1 Biometrics can prevent fraud without destroying privacy.</summary>
                <section class="more">
                    <p>
                        The article dismisses biometrics in two sentences, claiming that they "cut against data minimization goals."<span class="ref">[section 3.1]</span>. Arnold and Longley apparently believe that using biometrics must necessarily expose strong correlators to the verifier. Notice that they don't cite anybody or provide any reasoning to justify this assumption.
                    </p>
                    <p>
                        The same issue of <cite>IEEE Communications Standards</cite> magazine that published the Arnold Longley article includes an in-depth exploration of how biometrics can be combined cleverly with zero-knowledge proofs to achieve data minimization goals. <span class="ref">[12] It describes three usage patterns:</span>
                    </p>
                    <table>
                        <tr><th style="width:25%">Biometric Pattern</th><th>Trust characteristics</th></tr>
                        <tr>
                            <td>Pocket Pattern</td><td>Holder carries biometric template inside credential, and reveals it to verifier along with a fresh scan. Verifier evaluates match.</td>
                        </tr>
                        <tr>
                            <td>BSP Pattern</td><td>Holder carries biometric template inside credential, and reveals it to biometric service provider (BSP) along with a fresh scan. BSP attests match to verifier.</td>
                        </tr>
                        <tr>
                            <td>Low-fi Layers Pattern</td><td>Holder carries many low-fidelity biometric templates that each preserve herd privacy because of their imprecision. Multiple matches against low-fidelity templates can be layered to achieve exactly the privacy vs. trust tradeoff that circumstances demand, without the strong identification of ultra-high fidelity matches.</td>
                        </tr>
                    </table>
                    <p>
                        Even the Pocket Pattern, which has the least privacy of the three, achieves some data minimization by eliminating the need for issuers to build a database of biometrics as they issue. The BSP Pattern and the Low-fi Layers Pattern go beyond this, minimizing how much biometric data the verifier sees as well.
                    </p>
                    <p>
                        Although Arnold and Longley don't explain, they would likely discount the sort of interaction in the BSP pattern as introducing another trusted party; that is the basis of their critique of ABC4Trust's inspectors:
                    </p>
                    <blockquote>
                        We agree with ABC4Trust’s conclusion that the solution to the privacy-trust problem is an additional trusted party. But, if knowledge of the user’s identity and activity is ultimately necessary for maintaining their vulnerability, ZKPs should not be used to remove this knowledge in the first place.<span class="ref">[section 3.5]</span>
                    </blockquote>
                    <p>
                        But if that's their argument, note the false equivalence: <em>the BSP pattern trusts different parties for different things</em>. The BSP knows a biometric match is needed, but has no idea what credentials are involved, what else is being proved, or who the prover purports to be. The verifier knows that a biometric match is asserted by the BSP, but not what the biometric data in the credential <em>or</em> the biometric data from the most recent scan looks like. <em>That</em> is the cybersecurity principle of diffuse trust in action.<span class="ref">[<a id="reff" href="#notef">f</a>]</span> In contrast, the inspector model that Arnold and Longley criticize, and the trusted model they advocate, both show a third party exactly what the verifier would see if privacy were totally ignored. <em>That</em> is simple proxying. The trust and privacy implications are quite different.
                    </p>
                </section>
            </details>
            <details>
                <summary id="point4.2">4.2 Escrow can drastically change incentives for fraud.</summary>
                <section class="more">
                    <p>
                        The owner of a link secret can put into escrow either money or PII that any malicious actor can confiscate if Alice abuses trust. This drastically changes incentives for a malicious Alice.
                    </p>
                    <p>
                        For example, suppose Alice joins an online forum and wants to operate anonymously. The forum has a no-trolling, no-bullying policy. Alice uses verifiable encryption to encrypt her name and phone number (step 1 below), gives the encrypted payload to the forum (step 2a), and submits the key to decrypt this PII to the forum's independent escrow service (step 2b). Verifiable encryption means Alice can prove to the forum that she's encrypted her real PII, and that she's truly escrowed a key to unlock it.<span class="ref">[<a id="refg" href="#noteg">g</a>]</span> Alice can now operate anonymously (step 3) &mdash; but if the forum ever finds her guilty of abuse, it can approach the escrow service with proof of the abuse and get Alice's key so she can be de-anonymized (step 4). This is vulnerability, but it's conditional. And the condition is one that honorable provers can accept with little risk.
                    </p>
                    <figure id="escrow">
                        <img src="escrow.png" alt="Alice + forum + escrow service">
                        <figcaption>Figure 4: A simple escrow arrangement can protect both Alice and the forum.</figcaption>
                    </figure>
                    <p>
                        Arnold and Longley point out <span class="ref">[section 3.4]</span> that verifiers and provers both have to agree before such mechanisms become an option. This is true, and it should temper our enthusiasm to some degree. However, the article then dismisses the idea outright by claiming that escrow requires the verifier and prover to trust someone extra, and that this defeats the whole point of ZKPs.
                    </p>
                    <p>
                        As a narrow technical point, is is true that <em>something new</em> &mdash; the escrow mechanism &mdash; must be trusted <em>in some way</em> to use this approach. However, as with the discussion about biometric service providers (<a href="#point4.1">point 4.1</a>), equating the trust that must be placed in an escrow mechanism with the trust that must exist between verifier and prover is a mistake. The escrow mechanism doesn't need the least understanding of verifiable credentials or link secrets. It doesn't need to know that proving is taking place, or who's involved, or what's at stake, or any other context. It just needs to reliably release escrowed material according to pre-established rules. Furthermore, its conformance to those rules can be publicly audited without undermining Alice's privacy at all. This is not much different than trusting a phone to emit packets according to TCP/IP rules as we send an encrypted message; the mechanics of sending and the dynamics of trust established by the encryption are not really part of the same trust equation.
                    </p>
                    <p>
                        If any member of the public can approach the escrow service (e.g., "Alice abused trust by sharing her link secret, and I can prove it, because here it is."), and if the escrow service is willing to attest in zero knowledge to whether a particular escrow relationship is still active, then many of Arnold and Longley's other abuse scenarios are unlikely. The minute Alice abuses trust, she loses the secret as well as whatever value she escrowed as a bond &mdash; and the whole world can know it. Notice that the specific abuse of sharing link secrets disappears without proactive policing; the bond gives malicious parties an incentive to become the proactive enforcement without other parties lifting a finger.
                    </p>
                    <p>
                        Escrow is not a perfect tool. Alice could share her link secret with her sister, who could be dishonest with respect to the world but totally trustworthy toward Alice. However, escrow does alter the analysis of link secret reuse substantially. And the corner cases that it doesn't alter apply to non-ZKP-oriented credentials as well, as we'll see in point X.
                    </p>
                </section>
            </details>
            <details>
                <summary id="point4.3">4.3 Link secret reuse is detectable.</summary>
                <section class="more">
                    <p>
                        Under carefully structured ZKP conditions, a verifier can tell whether a link secret has already been used to prove something in a given context. This enables scenarios like "one person, one vote" or "one ticket, one admittance" while still providing reasonable anonymity for holders of ZKP-oriented credentials. The prover knows when challenged for proof that the verifier is using this technique, and can therefore refuse to cooperate; the verifier can detect whether the prover is cooperating. This gives each party the chance to opt out of a completed interaction.
                    </p>
                    <p>
                        The mathematics of this technique have been publicly described<span class="ref">[<a id="refh" href="#noteb">h</a>]</span> and will not be repeated here. Arnold and Longley "do not contest the mathematics of these schemes" <span class="ref">[Introduction]</span>, presumably including this specific application of them.
                    </p>
                    <p>
                        What Arnold and Longley do dispute, however, is the wisdom of using this technique, based on two concerns:
                    </p>
                    <ol>
                        <li><p>They claim that this form of reuse encourages correlation:</p>
                            <blockquote>
                                In the traditional case, users typically keep their different identities, or collections of attributes, separate from one another. Cross-identity information is never intended to be shared in clear or even encrypted form. Although this may inhibit the user’s ability to mix and match credentials across identities, it is the cost of keeping their identity linkage secret at all times. ZKP ABC systems that encourage users to mix all of their identities and attributes together introduce a new risk: correlation across identities.<span class="ref">[section 3.3]</span>
                            </blockquote>
                        </li>
                        <li>They assert that the link secret is given to the verifier in encrypted form; if crypto advances allow later decryption, this is a security and privacy risk.<span class="ref">[section 3.3]</span>
                        </li>
                    </ol>
                    <p>
                        Claim 1 is full of problems. It begins with the falsehood that "in the traditional case, users typically keep their different identities, or collections of attributes, separate from one another." In practice, just the opposite is true: holders of all credential types (ZKP-oriented or not) tend to coalesce all their identities in internal views, because to the holder, <em>all these attributes actually describe their singular, coherent identity</em>. We <em>want</em> this to be true; Alice shouldn't ignore how much she owes to lender 1 when she considers borrowing from lender 2, and she shouldn't ignore that she's a citizen of New Zealand when she applies for a passport from Italy. Alice the borrower and Alice the citizen and Alice the employee are mere projections of a unified whole, manifested externally per circumstances.
                    </p>
                    <p>
                        This is why users want one wallet to hold all of their credentials, not many. It's why they need help with hundreds of separate logins on the internet &mdash; the very reason why password managers exist as a product category. And it's why ZKP-oriented credentials use a link secret: to model in tech what already exists in the minds of the users, so software can manage it safely and intelligently on the user's behalf. ZKP-oriented credentials automatically generate unique projections of that identity in every interaction, precisely so things can look separate to an outside observer <em>without</em> the user having to worry about keeping all this stuff separate on the inside.
                    </p>
                    <p>
                        Introducing a technique to detect reuse of a link secret doesn't change incentives; it just shifts, very slightly, <em>who</em> can correlate. Normally the only person who sees the correlation is the holder, Alice; when the reuse dectection feature is used, the verifier becomes capable of an anemic form of correlation that prevents fraud, but it still can't identify her. This is not a risk of "correlation across identities" for an honest Alice, but it <em>is</em> an incentive not to attempt the fraudulent correlation of unrelated identities, for a malicious Alice.
                    </p>
                    <p>
                        The falsehood of claim 1's verbiage that "Cross-identity information is never intended to be shared in clear or even in encrypted form" has already been discussed (see <a href="#point1.3">point 1.3</a>).
                    </p>
                    <p>
                        Claim 1 is also wrong to assert that traditional ZKP use "may inhibit the user's ability to mix and match credentials across identities." Every alternative to link secrets, including all non-ZKP-oriented credential systems, creates significant obstacles to mixing and matching credentials across identities; only ZKP-oriented credentials offer an elegant, workable solution. Without them, users must either acquire huge numbers of "atomic credentials" that represent the exact permutations of attributes they want to share, or deal in elaborate merkle trees of signatures for each credential, or pay for and manage huge numbers of public DIDs, or leak unnecessary PII constantly. With them, users can have one driver's license, one passport, one birth certificate, and no public DIDs &mdash; and generate endless unique combinations of attributes on the fly, exactly suited to circumstances, while paying almost no attention to the underlying technicalities.
                    </p>
                    <p>So if claim 1 isn't a reasonable concern, what about claim 2? The only inference we can make from it is that Arnold and Longley deeply misunderstand the underlying cryptography, as discussed in detail in <a href="#point8">point 8</a>.</p>
                    <p>
                        The bottom line here is that it's easy, safe, and sometimes appropriate to detect link secret reuse. The technique is not mandatory, but it does give verifiers useful options. And this reinforces the larger point, which is that link secrets are a useful tool, if they're used wisely instead of naively as the article wants us to imagine. They can be combined with techniques like this one, or like escrow, or like biometrics, or like non-ZKP-like identifier disclosure, to achieve whatever level of assurance a verifier wants.
                    </p>
                </section>
            </details>
        </section>
    </details>

    <details>
        <summary id="point5">5. It misses nuances of repudiation.</summary>
        <section class="more">
            <p>
                When Alice proves something to Sofia in private using a credential, two separate repudiation questions arise:
            </p>
            <ol>
                <li>Can Alice later repudiate <em>to Sofia</em> the fact that she shared the credential, or what the credential contained?</li>
                <li>Can Alice later repudiate <em>to the public</em> the fact she shared the credential with Sofia, or what the credential contained?</li>
            </ol>
            <p>
                All credential technologies I know, including the ones oriented around ZKPs, enforce that the answer to Question 1 must be "No". Alice can't deny <em>to Sofia</em> what happened in private with Sofia.
            </p>
            <p>
                Question 2 is far more interesting. Arnold and Longley assert that the answer to this question, too, <em>must</em> be "No". Or more precisely, they don't recognize the distinction between these two questions, and the only answer they accept for the conflated combination is "No." If that's your position, then anything Alice proves to Sofia in confidence can later be revealed--by Sofia, by government subpoena, by a hacker, by a malicious sysadmin--and <em>proved</em>, publicly or to third parties. Alice gives away, forever, her control over proving whatever facts she shares with Sofia.
            </p>

            <figure id="whisper-secret">
                <img src="whisper-secret.jpg" alt="Alice whispers a secret to Sofia">
                <figcaption>Figure 3: Alice tells Sofia something confidential. What hopes might she have around Sofia's ability to reshare? (Image credit: <a target="_blank" href="https://www.flickr.com/photos/sophotow/16559284088">Wassim Loumi, CC SA 2.0, Flickr</a>, CC-SA Intl 4.0)</figcaption>
            </figure>

            <p>
                Sometimes, this is exactly what we want. If the proved fact is that Alice agreed to pay SofiaBank for a mortgage, then SofiaBank must be able to prove it in a court of law, regardless of Alice's cooperation.
            </p>
            <p>
                But what if Sofia is a medical researcher, and Alice is proving that she's HIV positive? Should Sofia be able prove Alice's HIV status to the public, just because Alice proved it to Sofia &mdash; or might we sometimes want this to require independent consent? What if Sofia works in a company's HR department, and Alice is proving her identity to Sofia so she can file a sexual harrassment complaint against her boss? Should Sofia be able to prove Alice's identity just because Alice proved it to her?
            </p>
            <p>
                Note that these same questions can also be framed in terms of a verifier's best interests. Would the medical researcher like the option of knowing Alice's HIV status, without having to insure against the risk that a hack will leak proof of HIV status to the public? Would Sofia in the HR department like to know for sure who Alice is, without worrying that a malicious sysadmin can "out" the victim?
            </p>
            <p>ZKP-oriented are nuanced and give the prover and verifier options; non-ZKP-oriented credentials are a blunt instrument:</p>
            <table>
                <tr>
                    <th>Question</th><th>ZKP answer</th><th>non-ZKP answer</th>
                </tr>
                <tr>
                    <td>Can Alice repudiate to Sofia?</td><td>No (enforced by crypto)</td><td rowspan="2">No (enforced by crypto)</td>
                </tr>
                <tr>
                    <td>Can Alice repudiate to others?</td><td>Maybe (verifier and prover agree in advance to terms of use; enforced by crypto)</td>
                </tr>
            </table>
            <p>
                ZKP-oriented credentials are fully capable of supporting public non-repudiation, like their simpler counterpart. If the verifier and prover agree that a proof will be non-repudiable (e.g., in the case of the mortgage), then the proof makes non-repudiation enforceable through the cryptography. This is, and always has been, the default behavior of the ZKP-oriented credentials in Hyperledger Indy. However, if the verifier and prover both agree that a proof should be repudiable to parties outside the private interaction (e.g., in the case of the HIV test), then the zero-knowledge proof can commit Alice only to Sofia; it's none of the public's business. No comparable option is available without zero-knowledge proofs. Therefore, ZKP-oriented credentials are more powerful with respect to repudiation than the alternative, not the opposite.
            </p>
            <p>Arnold and Longley appear not to understand this &mdash; perhaps because they assume (wrongly) that the only way to achieve non-repudiation is to disclose a signature value (see point X). Thus, many of the article's proximate and downstream arguments about repudiation fall apart.</p>
        </section>
    </details>

    <details>
        <summary id="point6">6. The trust gaps it highlights arise from foolish and unlikely assumptions, not ZKP properties.</summary>
        <section class="more">
            <p>
                Arnold and Longley build their case against ZKP-oriented credentials by imagining the need for evidence of "over 18" status [Introduction]. This is a common example used in ZKP literature, and it's fine as a starting point. But Arnold and Longley distort it by positing that a ZKP-oriented approach to this problem should begin with a <em>credential</em> containing exactly and only that assertion. This takes them far from reality; ZKP proponents would never agree to such a credential as a reasonable beginning. Why?
            </p>
            <ul>
                <li>Because the posited credential contains no issuance date or expiration date, the "over 18" status cannot be evaluated with respect to time &mdash; past, present, or future. <em>No issuer requires "over 18" without some reference to time; therefore the posited credential is useless even before we begin analyzing what proofs might be generated from it.</em></li>
                <li>Because the credential lacks any revocation feature, we can't evaluate whether its original issuer stands behind what they once asserted.</li>
                <li>Such a starting point conflates the distinction between a credential and a proof. What the verifier requires is <em>proof</em> of "over 18" &mdash; NOT whatever scraps of information can be gleaned from a <em>credential</em> of "over 18." A major purpose of ZKP-oriented credentials is to enable this distinction, so you prove "over 18" using whatever common, rich credentials are handy, like a driver's license or a passport. Such credentials are not "intended to communicate to the verifier Alice is over the age of 18" as Arnold and Longley want us to believe [Example 2.5] &mdash; they're intended to prove general facts that the holder can adapt to whatever proving requirements arise. They typically have dozens of useful fields, including birthdates instead of a boolean "over 18" assertion.</li>
            </ul>
            <p>
                Starting from a degenerate, fatally flawed credential that doesn't resemble any likely reality, Arnold and Longley argue that the proofs possible with their imagined credential have "trust gaps." <em>Of course</em> a credential with inadequate evidence will produce inadequate proof; this is a "begging the question" fallacy.
            </p>
            <p>
                A realistic scenario should actually look like more like this, assuming the behavior of a mature ZKP-oriented credential technology like the one in Hyperledger Indy &mdash; given that Alice possesses a digital driver's license, a verifier asks her to prove that:
            </p>
            <ol id="proof-details-list">
                <li>She possess a credential A,</li>
                <li>matching schema B (a canonical driver's license schema),</li>
                <li>containing field C (birthdate),</li>
                <li>where C contains a date value more than 18 years before today's date,</li>
                <li>and the credential is bound to Alice as holder with mechanism D so others can't use it,</li>
                <li>and the credential has an revocation index, E, which Alice knows,</li>
                <li>in revocation registry F,</li>
                <li>and the credential’s status in F is unrevoked</li>
                <li>and Alice know a signature G,</li>
                <li>from issuer H (the government authority that issues driver's licenses),</li>
                <li>endorsing the unmodified value C in the context of A, B, D, E, and F.</li>
            </ol>
            <p>
                Of course, the verifier need not track all these details in constructing a proof request, and Alice need not track them as she decides how to respond; technicalities can be (and typically are) handled by software. Both parties probably just understand the request as "prove with your unrevoked, valid driver's license that you're over age 18 today." However, the list above is a good approximation of what code actually manages with such a request. The options for generating and evaluating proof are much richer than what Arnold and Longley want us to imagine.
            </p>
            <details>
                <summary id="point6.1">6.1 Verifiers, not technology, create trust gaps.</summary>
                <section class="more">
                    <p>
                        So, what of the key conclusion of Arnold and Longley's Example 2.5 &mdash; that ZKPs anonymize the holder/prover, effectively erasing the part of the proof labeled "D" in the details above?
                    </p>
                    <p>
                        To answer that question, consider who does the erasing that creates the imagined trust gap. Is it the verifier, or the prover? If it's the verifier, then they're foolish; they've voluntarily opened themselves up to fraud by not requiring the prover to be the legitmate holder of the credential. If it's the prover, then the proof doesn't match the requirements of the verifier. Only a foolish verifier would accept that. Either way, a "trust gap" only occurs with a foolish verifier. Nothing in the tech requires verifiers to be foolish. In fact, the tech goes out of its way to provide wise, safe defaults. Plus, exactly the same sort of mistakes can occur with foolish verifiers and non-ZKP credentials: verifiers have been letting Alice use Carol's credit card since long before ZKP-oriented credentials were a thing. Trust gaps are a characteristic of careless interactions, not ZKPs.
                    </p>
                </section>
            </details>
        </section>
    </details>

    <details>
        <summary id="point7">7. It gets limited utility exactly backward.</summary>
        <section class="more">
            <p>The article claims that ZKP-oriented credentials "must introduce mechanisms that limit their utility."<span class="ref">[Abstract]</span> The word "must" is the problem here. It is true that some advanced features of ZKPs come with constraints, and we have discussed them in <a href="#point4">point 4</a> and <a href="#point5">point 5</a>. But contraints aren't news; they're an inherent characteristic of tradeoffs, typical of advanced features in any technology. Holders and verifiers don't have to depend on these features; they can limit themselves to just the capabilities of non-ZKP-oriented credentials if they like. But if they do access the extra options for privacy and repudiability that ZKP-oriented credentials offer, the use cases addressable with ZKPs become a superset of those addressable without them:</p>
            <figure id="addressable-use-cases">
                <img src="addressable-use-cases.png" alt="ZKP use cases are a superset; non-ZKP a subset">
                <figcaption>Figure 5: ZKP-addressable use cases are a superset of those addressable by the simpler alternative.</figcaption>
            </figure>
            <details>
                <summary id="point7.1">7.1 Various aspects of the "you can do more with ZKPs" assertion were proved elsewhere.</summary>
                <section class="more">
                    <p>
                        We saw in <a href="#point1">point 1</a> that by definition and intention, the boundaries of zero knowledge encompass all necessary facts. Using a far narrower and inaccurate definition, Arnold and Longley want us to believe that ZKP-oriented credentials are constrained by the purity of their zeroness to withhold vital facts from the verifier. But once the definition is corrected, this falls apart; zero knowledge proofs can match their non-zero-knowledge counterparts fact for fact. They just can't leak anything superfluous.
                    </p>
                    <p>
                        We saw in <a href="#point6">point 6</a> that the trust gaps imagined in the article have no dependence on ZKP properties.
                    </p>
                    <p>
                        We saw in <a href="#point4">point 4</a> that ZKP-oriented credentials support <em>all</em> of the same mechanisms to bind a holder to a credential as their non-ZKP-oriented counterparts &mdash; plus some unique options that non-ZKP-oriented credentials lack. Note that these are <em>options</em>. Just because the tech that creates these options is active does not mean that verifiers must use the options as their basis of trust.
                    </p>
                    <p>
                        ZKP-oriented credentials support the same non-repudiation options as their non-ZKP-oriented counterparts (see point X). The option for negotiated repudiability with respect to the public is a value-add with ZKPs; it lets the verifier and the holder pick different tradeoffs together if they like, but it does not force trust to be achieved a particular way.
                    </p>
                </section>
            </details>
            <details>
                <summary id="point7.2">7.2 Specific examples are abundant.</summary>
                <section class="more">
                    <p>
                        Here are some specific examples of how ZKP-oriented credentials solve problems that their simpler counterparts cannot:
                    </p>
                    <table>
                        <tr>
                            <th>Proof Requirements</th><th width="15%">Doable without ZKP?</th><th width="15%">Doable with ZKPs?</th>
                        </tr>
                        <tr><td>Use credentials to prove facts on a mortgage application, disclosing lots of Alice's PII</td><td class="nogap">Yes</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove Alice has an unexpired driver's license so she can rent a car, disclosing lots of Alice's PII</td><td class="nogap">Yes</td><td class="nogap">Yes</td></tr>
                        <tr><td>Use a special-purpose "over-18" credential to prove only that Alice is over 18</td><td class="nogap">Yes (if better than article's straw man)</td><td class="nogap">Yes (same caveat)</td></tr>
                        <tr><td>Use a driver's license or passport to prove only that Alice is over 18</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove to insurance company that Alice is HIV positive &mdash; publicly non-repudiable (researcher CAN pre-prove it)</td><td class="nogap">Yes</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove to medical researcher that Alice is HIV positive &mdash; publicly repudiable (researcher CAN'T re-prove it)</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove to Acme that a newly enrolled user is named Alice, and then prove it again later, without Acme being able to tell whether it's the same Alice</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove to Acme's HR dept only that Alice is a female employee in the Houston office, so she can make a semi-anonymous sexual harrassment complaint</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove only that Alice, identified strongly, has a credit score between 750 and 800, without revealing what the score is.</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove only that Alice is female, over 45, lives in one of 10 postal codes, and has an annual income of six figures, without revealing further details.</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove only that Alice possesses an unexpired major credit card, without revealing further details.</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove only that Alice is a registered voter who hasn't already voted in an election, without identifying her.</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove only that credential A and credential B were issued to the same person, without revealing additional information.</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Remotely prove that Alice is bound to a credential by a biometric, without disclosing the biometric to verifier.</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                        <tr><td>Prove that Alice is bound to a credential by a link secret, where the secret is still protected by a bond that can be confiscated by any malicious party that knows it.</td><td class="gap">No</td><td class="nogap">Yes</td></tr>
                    </table>
                </section>
            </details>
        </section>
    </details>

    <details>
        <summary id="point8">8. It is wrong about ZKPs being especially vulnerable to advances in crypto.</summary>
        <section class="more">
            <p>An important claim in the abstract is that with ZKP-oriented credentials, "[g]reater trust must be placed in the shelf life of cryptography to prevent the user from being unwantonly correlated than alternative approaches." [Abstract] The basis of this claim is elaborated in section 3.3, which incorrectly asserts:
            </p>
            <blockquote>
                ZKP ABC systems that encourage users to mix all of their identities and attributes together introduce a new risk: correlation across identities. Such systems use information hiding, or encryption, to enable a user to prove that their attributes are linked together. The user presents a value that has been mathematically modified by their correlation secret to the verifier. The expectation is that this operation cannot be reversed by the verifier. Each time they encrypt their correlation secret, they expose a different value, unless they are using link secret reuse to fill trust gaps. A user in this system is giving to every verifier an encrypted copy of the secret binding all of their identities together. This may be particularly surprising since the very party the user is trying to keep this information away from is the verifier. Fear that the verifier may correlate their information in undesirable ways is the whole reason for utilizing ZKPs. Since the encrypted secret is given directly to the verifier, user privacy is at the mercy of the security of the cryptographic scheme used. For example, if this cryptography is not quantum resistant, then a future quantum computer could decrypt this information. Revealing links across all of a user’s various identities and attributes catastrophically eliminates the user’s privacy.
            </blockquote>
            <p>
                The problem with this narrative is that it's based on a false equivalence. Encryption is generally acknowledged to have a limited shelf-life due to advances in cryptanalysis and computing power. Because of this, it suits the authors' purposes to have us to believe that link secrets are shared by encrypting them. If this were true, then link secrets might be vulnerable as Arnold and Longley claim (though they vastly exaggerate the impact, anyway).[] But link secrets aren't shared by encrypting them; in fact, they aren't <em>shared</em> at all. Instead, they bind their owner using a technique called <dfn>cryptographic commitments</dfn>. Commitment schemes are the mathematical equivalent of a secure coin flip. They require Alice to make and share <em>a commitment</em> to a value V at time T, require her to prove characteristics of V at time T+N, and guarantee mathematically that she can't change which V she chose to manipulate the outcome. If she picked heads, she can't claim she picked tails. If she is using link secret X, she can't substitute link secret Y[]
            </p>
            <p>
                Notice what's shared in such a scheme: a commitment, not an encrypted secret.
            </p>
            <p>
                Both encryption and cryptographic commitments are forms of information hiding, and the article invites us to cross a mental bridge through that commonality: "...[s]uch systems use information hiding, or encryption." But the bridge is a mistake. Consider:
            </p>
            <ul>
                <li>Hiding my password on post-it notes in a desk drawer is a form of information hiding, but that doesn't make it encryption.</li>
                <li>Deleting data on my hard drive is a form of information hiding, but that doesn't make it encryption.</li>
                <li>Turning a gigabyte of my genome into a SHA-256 hash digest is a form of information hiding, but that doesn't make it encryption.</li>
            </ul>
            <p>
                Encryption has a complementary operation called decryption. This is what faster computers with better cracking algorithms might do. But cryptographic commitments have no such complement. They are nowhere near as reversible as encryption.
            </p>
            <p>
                Cryptographic commitments are a bit like shadows. By inspecting a shadow, you can tell something about the object that cast it. You know the object existed, and you can estimate its visual magnitude at the point where it interrupted the light. You also know something about its shape. However, you cannot reconstruct a three-dimensional object from a two-dimensional shadow; an infinite number of three-dimensional objects could interrupt light in the same way. They could have any color or texture or mass or orientation.
            </p>
            <figure id="3-shadows">
                <img src="3-shadows.png" alt="the same shadow can be cast by an infinite number of objects">
                <figcaption>Figure X: the same shadow can be cast by an infinite number of objects.</figcaption>
            </figure>
            <p>
                Similarly, the evidence of a cryptographic commitment that's embedded in a ZKP credential can be used to prove to a verifier that the holder knows the secret &mdash; but it can't be used to "decrypt" the link secret, because what's there is only a one-way projection of the original value, not a complete, reversible transformation of it.
            </p>
        </section>
    </details>

    <details>
        <summary id="point9">9. Its credential proxying scenario applies at least as well to credentials that don't use ZKPs.</summary>
    </details>

    <details>
        <summary id="summary">Summary (where we agree and disagree)</summary>
        <section class="more">
            <table>
                <tr><th style="width:45%">Idea</th><th>AL article</th><th style="width:45%">Authors of this rebuttal</th></tr>
                <tr>
                    <td>Absolute anonymity is not desirable in many contexts. A bank won't give a mortage to a lender they can't take to court.</td>
                    <td>Yes</td>
                    <td>Yes. And we'd note that absolute anonymity is almost never possible, even if it were desirable. See point x.</td>
                </tr>
                <tr>
                    <td>ZKP-oriented credentials aim for / enforce absolute anonymity of the holder.</td>
                    <td>Yes</td>
                    <td>No, they aim to <em>improve</em> the anonymity. See point x.</td>
                </tr>
                <tr>
                    <td>When a verifier agrees to accept less assurance about attributes of a holder, they are making a trust tradeoff.</td>
                    <td>Yes</td>
                    <td>Yes. This is true with all credentials.</td>
                </tr>
                <tr>
                    <td>Strongly identified holders are more likely to be trusted in some contexts.</td>
                    <td>Yes</td>
                    <td>Yes. The longer ZKP technology remains misunderstood, the truer this will be.</td>
                </tr>
                <tr>
                    <td>A holder/prover must be vulnerable to a verifier before it is reasonable to trust them.</td>
                    <td>Yes</td>
                    <td>No. A verifier must know that the holder/prover is constrained <em>enough</em> by incentives, context, technical possibilities, history, reputation, and similar factors to match the desired level of assurance. Trust isn't binary, and it's not purely reputation-based. Likewise, a holder/prover must know something about verifier constraints to extend trust the other way. See point x.</td>
                </tr>
                <tr>
                    <td>Holders/provers must interact in a non-repudiable way in all cases, to be trustworthy.</td>
                    <td>Yes.</td>
                    <td>No. This is a good default, but there are meaningful corner cases where a repduiable proof is important. See point x.</td>
                </tr>
                <tr>
                    <td>ZKP-oriented credentials force verifiers to trust link secrets or to reject the tech.</td>
                    <td>Yes</td>
                    <td>No. Correlation secrets are always available to use, but verifiers can choose to trust them or not, per preference and circumstances. See point x.</td>
                </tr>
                <tr>
                    <td>A proof that discloses a person's name can be zero knowledge.</td>
                    <td>No</td>
                    <td>Yes. See point X.</td>
                </tr>
                <tr>
                    <td>A proof that discloses a person's name with ZKP-oriented credentials amounts to the same thing as showing a credential with only the person's name.</td>
                    <td>Yes.</td>
                    <td>No. With ZKPs, the existence and validity of the issuer's signature, rather than its value, gets disclosed. Sometimes this difference matters. See point x.</td>
                </tr>
                <tr>
                    <td>ZKP-oriented credentials can't be reliably bound to their holder.</td>
                    <td>Yes.</td>
                    <td>No. See point x.</td>
                </tr>
                <tr>
                    <td>Biometrics aren't relevant to ZKP-oriented credentials, since they are guaranteed to disclose strong correlators.</td>
                    <td>Yes.</td>
                    <td>No. See point x.</td>
                </tr>
                <tr>
                    <td>ZKP-oriented credentials are inherently susceptible to a proxy attack.</td>
                    <td>Yes.</td>
                    <td>No. They are susceptible or not to the degree that verifiers make foolish choices about what proof they'll accept, and advanced binding protections aren't used. This is also true of non-ZKP-oriented credentials. See point X.</td>
                </tr>
                <tr>
                    <td>ZKP-oriented credentials contain an encrypted copy of a link secret, and presentations derive from them give an encrypted copy of that secret to verifiers. Therefore they are susceptible to decryption if cryptography advances.</td>
                    <td>Yes.</td>
                    <td>No. This is a misunderstanding of a technique called cryptographic commitments. See point X.</td>
                </tr>
                <tr>
                    <td>ZKP-oriented credentials encourage correlation.</td>
                    <td>Yes.</td>
                    <td>No. Just the opposite. See point X.</td>
                </tr>
                <tr>
                    <td>ZKP-oriented credentials are only useful in corner cases.</td>
                    <td>Yes.</td>
                    <td>No. Use cases addressable with ZKP-oriented credentials is a superset of the ones addressable without them. See point X.</td>
                </tr>
            </table>
        </section>
    </details>

    <details>
        <summary id="learningmore">Learning more</summary>
        <section class="more">
            <p>"traditional"</p>
            <p>correlation and privacy</p>
            <p>Evernym's blog</p>
            <p>threat model for VCs</p>
        </section>
    </details>

    <details>
        <summary id="endnotes">Endnotes</summary>
        <section class="more">
            <p id="notea"><span class="ref">[<a href="#refa">a</a>]</span>&nbsp; See Yehuda Liddell's comments on this very distinction, on StackOverflow: https://crypto.stackexchange.com/questions/37056/zero-knowledge-proof-system-which-is-not-proof-of-knowledge/37060#37060.</p>
            <p id="noteb"><span class="ref">[<a href="#refb">b</a>]</span>&nbsp; https://blog.ethereum.org/2016/12/05/zksnarks-in-a-nutshell/</p>
            <p id="note1"><span class="ref">[<a href="#ref1">1</a>]</span>&nbsp; Many amateur and journeyman discussions of ZKPs online offer the same conflated description as Arnold and Longley. This is because they are either unaware of the distinction, or the distinction doesn't matter in their context. <a target="source" href="https://en.wikipedia.org/wiki/Zero-knowledge_proof#Definition">The Wikipedia article on ZKPs</a> (retrieved Jan 16, 2020) is inconsistent. In its Definition section, Wikipedia gives a correct, general ZKP formulation: "if the statement is true, no verifier learns anything other than the fact that the statement is true." And in the introduction, it also notes correctly: "A zero-knowledge proof of knowledge is a special case when the statement consists only of the fact that the prover possesses the secret information." However, earlier text in the introduction slips into the ZKP=ZKPOK conflation: "In cryptography, a zero-knowledge proof or zero-knowledge protocol is a method by which one party (the prover) can prove to another party (the verifier) that they know a value <var>x</var>, without conveying any information apart from the fact that they know the value <var>x</var>."</p>

            <p id="notec"><span class="ref">[<a href="#refc">c</a>]</span>&nbsp; See this discussion about the law on wecard.org: http://bit.ly/2KcuUCq</p>
            <p id="noted"><span class="ref">[<a href="#refd">c</a>]</span>&nbsp; https://www.nap.edu/read/18997/chapter/8</p>
            <p id="notee"><span class="ref">[<a href="#refe">e</a>]</span>&nbsp; https://www.darkreading.com/perimeter/the-3-cybersecurity-rules-of-trust-/a/d-id/1334732
            <p id="notef"><span class="ref">[<a href="#reff">f</a>]</span>&nbsp; https://github.com/WebOfTrustInfo/rwot7-toronto/blob/master/topics-and-advance-readings/ZeroTrustComputingWithDidsAndDads.md. Also Trust and multi-agent systems: applying the “diffuse, default model” of trust to experiments involving artificial agents
            J Buechner, HT Tavani - Ethics and information Technology, 2011 - Springer. Also https://www.andysayler.com/output/pdf/phd-dissertation-report.pdf. Also the discussion of sybil attacks here: https://www.researchgate.net/publication/326094774_Bubbles_of_Trust_a_decentralized_Blockchain-based_authentication_system_for_IoT. Also page 98 of https://books.google.com/books?id=oHp8DwAAQBAJ&pg=PA98&lpg=PA98&dq=diffuse+trust+blockchain&source=bl&ots=WNtSacmdlA&sig=ACfU3U2ztWdeoRb7wETBn7AAlMvx4XCl-g&hl=en&sa=X&ved=2ahUKEwjJquPmvKfnAhWLG80KHTVaDj4Q6AEwCnoECAkQAQ#v=onepage&q=diffuse%20trust%20blockchain&f=false</p>
            <p id="noteg"><span class="ref">[<a href="#refg">g</a>]</span>&nbsp; https://www.shoup.net/papers/verenc.pdf; also https://eprint.iacr.org/2017/122.pdf</p>
            <p id="noteh"><span class="ref">[<a href="#refh">h</a>]</span>&nbsp; https://github.com/WebOfTrustInfo/rwot9-prague/blob/master/topics-and-advance-readings/zkp-safety.md#technique-2-prevent-link-secret-reuse</p>
            <p id="notej"><span class="ref">[<a href="#refj">j</a>]</span>&nbsp; The watermarks derived from a master image typically resemble the originally very strongly, because they are meant to be checked for likeness by an untrained human eye. On the other hand, the cryptographic commitments derived from a link secret and embedded in credentials use a one-way transformation such that they can't be reversed, either in the credential or in later proofs that knowledge of the link secret. This is a major aspect of ZKP cryptography that Arnold and Longley get wrong. See <a href="#point8">point 8</a>.
            </p>
            <p><span class="ref" style="color:white">[1]</span>&nbsp; Expert cryptographers are often more careful. See, for example, <a target="source" href="https://eprint.iacr.org/2009/211.pdf">a paper from the Security Protocols XVII conference</a>, <a target="source" href="https://www.cs.umd.edu/~jkatz/gradcrypto2/f13/lecture17.pdf">notes from a University of Maryland graduate cryptography course</a>, <a target="source" href="https://z.cash/technology/zksnarks/">the Zcash intro to ZK-SNARKs</a>, <a target="source" href="https://scapi.readthedocs.io/en/latest/interactive_layer/zk.html">these docs from SCAPI (a secure computation library)</a>, or <a target="source" href="https://eprint.iacr.org/2010/552.pdf">an academic paper on ZKPOKs by Hazay and Lindell</a>.</p>

            <p><span class="ref" style="color:white">[1]</span>&nbsp; For a better primer on ZKPs than Wikipedia, try <a target="source" href="https://towardsdatascience.com/what-are-zero-knowledge-proofs-7ef6aab955fc">this one from towardsdatascience.com</a>. Notice that the "Where's Waldo" illustration it offers involves disclosure (showing Waldo's picture), not just proof of knowledge.</p>

            <p id="note2"><span class="ref">[<a href="#ref2">2</a>]</span>&nbsp; S. Goldwasser, S. Micali, and C. Rackoff, "The knowledge complexity of interactive proof-systems, <cite>SIAM Journal on Computing</cite>, 18(1), 1989, pp. 186-208. <a target="source" href="http://j.mp/2u69dQe">http://j.mp/2u69dQe</a>. Note that this paper existed in some form as early as 1982. There’s a 1985 version, published for the IEEE Foundations of Computer Science conference that defines the adjective “0-knowledge” &mdash; but it is the 1989 version that gives the simple formulation above and that is most available today.</p>

            <p id="note3"><span class="ref">[<a href="#ref3">3</a>]</span>&nbsp; See points 3 and 4 in "Core Fallacies", <cite>Stanford Encyclopedia of Philosophy</cite>, <a target="source" href="http://j.mp/2TAy4GC">http://j.mp/2TAy4GC</a>.</p>

            <p id="notea4"><span class="ref">[<a href="#ref4">4</a>]</span>&nbsp; "The rush for zero-knowledge proofs, and where it leaves privacy coins". Hackernoon. Dec 2018. <a target="source" href="http://j.mp/3aewsbc">http://j.mp/3aewsbc</a>.</p>

            <p id="note5"><span class="ref">[<a href="#ref5">5</a>]</span>&nbsp; See, for example, Blazy, O., Derler, D., Slamanig, D., and Spreitzer, R. "Non-Interactive Plaintext (In-)Equality Proofs and Group Signatures with Verifiable Controllable Linkability". <cite>Topics in Cryptology - CT-RSA</cite>, 2016. <a target="source" href="https://eprint.iacr.org/2016/082.pdf">https://eprint.iacr.org/2016/082.pdf</a>. Related implementation in Hyperledger Ursa at <a target="source" href="http://j.mp/374Lrmb">http://j.mp/374Lrmb</a>.</p>

            <p id="note6"><span class="ref">[<a href="#ref6">6</a>]</span>&nbsp; See, for example, Gosh, E., Ohrimenko, O., and Tomassia, R. "Verifiable Member and Order Queries on a List in Zero-Knowledge". Brown University, 2014. <a target="source" href="http://j.mp/38grw3L">http://j.mp/38grw3L</a>. Implementation of a similar concept in Hyperledger Ursa at <a target="source" href="http://j.mp/2Rqeb2g">http://j.mp/2Rqeb2g</a>.</p>

            <p id="note7"><span class="ref">[<a href="#ref7">7</a>]</span>&nbsp; For examples of scholarly research, see Benarroch, D., Campanelli, M., Fiore, D., and Kolonelos, D. "Zero-Knowledge Proofs for Set Membership: Efficient, Succinct, Modular". International Association for Cryptologic Research. Oct 2019. <a target="source" href="https://eprint.iacr.org/2019/1255.pdf">https://eprint.iacr.org/2019/1255.pdf</a>. Also Camenisch, J., Chaabouni, R., and Shelat, A. "Efficient Protocols for Set Membership and Range Proofs." AsiaCrypt, 2008. <a target="source" href="http://j.mp/2FXDKPQ">http://j.mp/2FXDKPQ</a>. Implementation in Hyperledger Ursa at <a target="source" href="http://j.mp/370plBc">http://j.mp/370plBc</a> and <a target="source" href="http://j.mp/360S9In">http://j.mp/360S9In</a>.</p>

            <p id="note8"><span class="ref">[<a href="#ref8">8</a>]</span>&nbsp; ZCash uses ZK-SNARKs to disclose some details of a transaction while hiding others. Disclosing values, including pseudonyms, has been a feature of Sovrin-style ZKP-oriented credentials since they were first released (personal knowledge). An implementation of ZKP disclosure exists in Hyperledger Ursa at <a target="source" href="http://j.mp/2NDvyeH">http://j.mp/2NDvyeH</a>.</p>

            <p id="note9"><span class="ref">[<a href="#ref0">9</a>]</span>&nbsp; Bichsel P., et al. <cite>D2.2 - Architecture for Attribute-based Credential Technologies - Final Version</cite>, Goethe University, IBM Research, and Microsoft NV, 2014. <a target="source" href="http://j.mp/30th3zq">http://j.mp/30th3zq</a>.
            </p>

        </section>
    </details>
</article>

</body>

</html>